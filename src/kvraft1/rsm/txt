package rsm

import (
	"sync"
	"time"

	"6.5840/kvsrv1/rpc"
	"6.5840/labrpc"
	"6.5840/raft1"
	"6.5840/raftapi"
	"6.5840/tester1"
)

var useRaftStateMachine bool // to plug in another raft besided raft1

type Op struct {
	// Your definitions here.
	// Field names must start with capital letters,
	// otherwise RPC will break.
	Id  int64 // 唯一操作ID
	Req any   // 实际的请求内容
}

// A server (i.e., ../server.go) that wants to replicate itself calls
// MakeRSM and must implement the StateMachine interface.  This
// interface allows the rsm package to interact with the server for
// server-specific operations: the server must implement DoOp to
// execute an operation (e.g., a Get or Put request), and
// Snapshot/Restore to snapshot and restore the server's state.
// 一个希望实现自我复制的服务器（例如，在 ../server.go中）会调用 MakeRSM，
// 并且必须实现 StateMachine接口。这个接口允许 rsm包与服务器进行交互，
// 以执行特定于服务器的操作：服务器必须实现 DoOp方法来执行一个操作
// （例如，一个 Get 或 Put 请求），并实现 Snapshot/Restore方法来
// 对服务器的状态进行快照和恢复。
type StateMachine interface {
	DoOp(any) any
	Snapshot() []byte
	Restore([]byte)
}

type RSM struct {
	mu           sync.Mutex
	me           int
	rf           raftapi.Raft
	applyCh      chan raftapi.ApplyMsg
	maxraftstate int // snapshot if log grows this big
	sm           StateMachine
	// Your definitions here.
	nextOpId     int64                       // 下一个操作ID
	pendingOps   map[int]*PendingOp          // 等待结果的操作: index -> pending op info
	lastApplied  int                         // 最后应用的日志索引
}

// PendingOp 存储等待结果的操作信息
type PendingOp struct {
	OpId     int64          // 期望的操作ID
	Term     int            // 提交时的term
	ResultCh chan OpResult  // 结果channel
}

// OpResult 封装操作的执行结果
type OpResult struct {
	Value any     // DoOp()的返回值
	Err   rpc.Err // 错误信息
}

// servers[] contains the ports of the set of
// servers that will cooperate via Raft to
// form the fault-tolerant key/value service.
//
// me is the index of the current server in servers[].
//
// the k/v server should store snapshots through the underlying Raft
// implementation, which should call persister.SaveStateAndSnapshot() to
// atomically save the Raft state along with the snapshot.
// The RSM should snapshot when Raft's saved state exceeds maxraftstate bytes,
// in order to allow Raft to garbage-collect its log. if maxraftstate is -1,
// you don't need to snapshot.
//
// MakeRSM() must return quickly, so it should start goroutines for
// any long-running work.
// servers[] 包含了那些将通过 Raft 协议进行协作、
// 共同构成容错键值服务的一组服务器的端口号。

// me 是当前服务器在 servers[] 中的索引。

// 键值（k/v）服务器应通过底层的 Raft 实现来存储快照。
// Raft 会调用 persister.SaveStateAndSnapshot() 来原子性地保存其状态以及快照。
// 当 Raft 已保存的状态大小超过 maxraftstate 字节时，RSM 应当生成快照，
// 以便让 Raft 能够对其日志进行垃圾回收。如果 maxraftstate 为 -1，
// 则表示您不需要生成快照。

// MakeRSM() 函数必须快速返回，因此对于任何耗时较长的任务，
// 它应该启动新的 goroutine 来执行。
func MakeRSM(servers []*labrpc.ClientEnd, me int, persister *tester.Persister, maxraftstate int, sm StateMachine) *RSM {
	rsm := &RSM{
		me:           me,
		maxraftstate: maxraftstate,
		applyCh:      make(chan raftapi.ApplyMsg),
		sm:           sm,
		nextOpId:     0,
		pendingOps:   make(map[int]*PendingOp),
		lastApplied:  0,
	}
	if !useRaftStateMachine {
		rsm.rf = raft.Make(servers, me, persister, rsm.applyCh)
	}

	// 启动reader goroutine来处理已提交的操作
	go rsm.reader()

	return rsm
}

func (rsm *RSM) Raft() raftapi.Raft {
	return rsm.rf
}

// Submit a command to Raft, and wait for it to be committed.  It
// should return ErrWrongLeader if client should find new leader and
// try again.
func (rsm *RSM) Submit(req any) (rpc.Err, any) {

	// Submit creates an Op structure to run a command through Raft;
	// for example: op := Op{Me: rsm.me, Id: id, Req: req}, where req
	// is the argument to Submit and id is a unique id for the op.

	// your code here
	rsm.mu.Lock()
	opId := rsm.nextOpId
	rsm.nextOpId++
	op := Op{
		Id:  opId,
		Req: req,
	}
	rsm.mu.Unlock()

	// 调用Raft的Start()提交操作
	index, term, isLeader := rsm.rf.Start(op)
	if !isLeader {
		return rpc.ErrWrongLeader, nil
	}

	// 创建channel等待结果
	rsm.mu.Lock()
	resultCh := make(chan OpResult, 1)
	rsm.pendingOps[index] = &PendingOp{
		OpId:     opId,
		Term:     term,
		ResultCh: resultCh,
	}
	rsm.mu.Unlock()

	// 等待操作被提交并执行
	// 同时定期检查term是否改变（说明leadership已改变）
	ticker := time.NewTicker(10 * time.Millisecond)
	defer ticker.Stop()

	for {
		select {
		case result := <-resultCh:
			rsm.mu.Lock()
			delete(rsm.pendingOps, index)
			rsm.mu.Unlock()
			return result.Err, result.Value

		case <-ticker.C:
			// 定期检查term是否改变
			currentTerm, isLeader := rsm.rf.GetState()
			if !isLeader || currentTerm != term {
				// Leadership已改变，清理并返回错误
				rsm.mu.Lock()
				delete(rsm.pendingOps, index)
				rsm.mu.Unlock()
				return rpc.ErrWrongLeader, nil
			}
		}
	}
}

// reader goroutine从applyCh读取已提交的操作并执行
func (rsm *RSM) reader() {
	for msg := range rsm.applyCh {
		if msg.CommandValid {
			rsm.mu.Lock()

			// 获取当前term
			term, _ := rsm.rf.GetState()

			// 执行操作
			op, ok := msg.Command.(Op)
			if !ok {
				rsm.mu.Unlock()
				continue
			}

			// 调用StateMachine的DoOp执行操作
			value := rsm.sm.DoOp(op.Req)

			// 更新lastApplied
			rsm.lastApplied = msg.CommandIndex

			// 通知等待的Submit()调用
			if pendingOp, exists := rsm.pendingOps[msg.CommandIndex]; exists {
				// 检查是否是期望的操作
				if pendingOp.OpId == op.Id && pendingOp.Term == term {
					// 操作匹配，返回成功结果
					result := OpResult{
						Value: value,
						Err:   rpc.OK,
					}
					// 非阻塞发送
					select {
					case pendingOp.ResultCh <- result:
					default:
					}
				} else {
					// 操作不匹配（leadership已改变），返回错误
					result := OpResult{
						Value: nil,
						Err:   rpc.ErrWrongLeader,
					}
					// 非阻塞发送
					select {
					case pendingOp.ResultCh <- result:
					default:
					}
				}
			}

			rsm.mu.Unlock()
		} else if msg.SnapshotValid {
			// Part C will handle snapshots
			rsm.mu.Lock()
			rsm.sm.Restore(msg.Snapshot)
			rsm.lastApplied = msg.SnapshotIndex
			rsm.mu.Unlock()
		}
	}
}
